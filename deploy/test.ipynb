{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c40ee6-b021-4d1e-95e6-d0769dcd1ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41114552-c36a-40c8-9ef2-93882681cdcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/root/autodl-tmp/BertClassNews/\")\n",
    "from train.utils import *\n",
    "from config.config import *\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "\n",
    "config = Config().model_config\n",
    "model = config.model\n",
    "model = save_model(model, config)\n",
    "# model.to(config.device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb26354-3093-450a-b231-9b5a4d7fe257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('/root/autodl-tmp/BertClassNews/BertClass/bert_seq_class.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8595c2-b6f5-44e9-97f9-c26f53c00035",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/root/autodl-tmp/BertClassNews/BertClass/bert_vocab.txt',)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = config.tokenizer\n",
    "tokenizer.save_vocabulary('/root/autodl-tmp/BertClassNews/BertClass/bert_vocab.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe78667f-a594-44cd-bbe3-6a5984ab0d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import subprocess\n",
    "\n",
    "# Save to .pth.tar\n",
    "torch.save(model.state_dict(), '/root/autodl-tmp/BertClassNews/BertClass/model.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "747ccc24-6b02-41e3-8194-bc5982cf657d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a0e581-62e1-4e08-b31a-1061e7b30004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "  warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n'Optional[Tensor]' object has no attribute or method 'size'.:\n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 213\n            input_shape = input_ids.size()\n        else:\n            input_shape = inputs_embeds.size()[:-1]\n                          ~~~~~~~~~~~~~~~~~~ <--- HERE\n    \n        seq_length = input_shape[1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scripted_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# scripted_model.save('/root/autodl-tmp/BertClassNews/BertClass/bert.pt')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# scripted_model.save('bert.pt')\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_script.py:1284\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m   1283\u001b[0m     obj \u001b[38;5;241m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[0;32m-> 1284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_script_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_methods_to_compile\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_script_dict(obj)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_recursive.py:480\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    479\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_recursive.py:542\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    539\u001b[0m     script_module\u001b[38;5;241m.\u001b[39m_concrete_type \u001b[38;5;241m=\u001b[39m concrete_type\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m script_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursiveScriptModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpp_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_script.py:614\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03mcode should use this to construct a RecursiveScriptModule instead\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    613\u001b[0m script_module \u001b[38;5;241m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 614\u001b[0m \u001b[43minit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    618\u001b[0m RecursiveScriptModule\u001b[38;5;241m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_recursive.py:520\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    517\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m orig_value\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_concrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m cpp_module\u001b[38;5;241m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    523\u001b[0m script_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m scripted\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_recursive.py:542\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    539\u001b[0m     script_module\u001b[38;5;241m.\u001b[39m_concrete_type \u001b[38;5;241m=\u001b[39m concrete_type\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m script_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecursiveScriptModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpp_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_script.py:614\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03mcode should use this to construct a RecursiveScriptModule instead\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;124;03m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    613\u001b[0m script_module \u001b[38;5;241m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 614\u001b[0m \u001b[43minit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    618\u001b[0m RecursiveScriptModule\u001b[38;5;241m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_recursive.py:520\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    517\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m orig_value\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;66;03m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     scripted \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_concrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m cpp_module\u001b[38;5;241m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    523\u001b[0m script_module\u001b[38;5;241m.\u001b[39m_modules[name] \u001b[38;5;241m=\u001b[39m scripted\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_recursive.py:546\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n\u001b[0;32m--> 546\u001b[0m     \u001b[43mcreate_methods_and_properties_from_stubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_stubs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_stubs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;66;03m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/jit/_recursive.py:397\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    394\u001b[0m property_defs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdef_ \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[1;32m    395\u001b[0m property_rcbs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mresolution_callback \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[0;32m--> 397\u001b[0m \u001b[43mconcrete_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_methods_and_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperty_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defaults\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n'Optional[Tensor]' object has no attribute or method 'size'.:\n  File \"/root/miniconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 213\n            input_shape = input_ids.size()\n        else:\n            input_shape = inputs_embeds.size()[:-1]\n                          ~~~~~~~~~~~~~~~~~~ <--- HERE\n    \n        seq_length = input_shape[1]\n"
     ]
    }
   ],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "# scripted_model.save('/root/autodl-tmp/BertClassNews/BertClass/bert.pt')\n",
    "# scripted_model.save('bert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52876691-d3a0-4842-96e3-ff773c004db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/root/autodl-tmp/BertClassNews/load_dataset')\n",
    "from load_data_cls import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2dd17cd-ba6a-499f-8279-bf5fe2f44c39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadDat_Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mloadDat_Config\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loadDat_Config' is not defined"
     ]
    }
   ],
   "source": [
    "config = loadDat_Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a961cd57-dae1-4ac4-9128-33536864e1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting flask\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/36/42/015c23096649b908c809c69388a805a571a3bea44362fe87e33fc3afa01f/flask-3.0.0-py3-none-any.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 6.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting Werkzeug>=3.0.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/b6/a5/54b01f663d60d5334f6c9c87c26274e94617a4fd463d812463626423b10d/werkzeug-3.0.0-py3-none-any.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting itsdangerous>=2.1.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/68/5f/447e04e828f47465eeab35b5d408b7ebaaaee207f48b7136c5a7267a30ae/itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.1.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 41.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blinker>=1.6.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/0d/f1/5f39e771cd730d347539bb74c6d496737b9d5f0a53bc9fdbf3e170f1ee48/blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /root/miniconda3/lib/python3.8/site-packages (from flask) (6.0.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /root/miniconda3/lib/python3.8/site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from Jinja2>=3.1.2->flask) (2.1.2)\n",
      "Installing collected packages: Werkzeug, itsdangerous, click, blinker, flask\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 2.2.3\n",
      "    Uninstalling Werkzeug-2.2.3:\n",
      "      Successfully uninstalled Werkzeug-2.2.3\n",
      "Successfully installed Werkzeug-3.0.0 blinker-1.6.2 click-8.1.7 flask-3.0.0 itsdangerous-2.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5740f9-9e9b-4a90-b08c-aeddf576634f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  __pycache__  load_data_cls.py  test.ipynb\ttest.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f5d9855-ffb5-4543-964a-df23743b6ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./load_dataset/')\n",
    "# os.chdir('/root/autodl-tmp/BertClassNews/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3467a22a-b93f-4bd5-bafb-c4566db9809b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/root/autodl-tmp/BertClassNews/load_dataset',\n",
       " '/root/miniconda3/lib/python38.zip',\n",
       " '/root/miniconda3/lib/python3.8',\n",
       " '/root/miniconda3/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/root/miniconda3/lib/python3.8/site-packages']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22532f94-2ffc-4920-9514-978a735c85cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# config = aug_Config()\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "from config.config import * \n",
    "# config = aug_Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8fa2a-f123-4d61-b219-c7fa312a549c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = Config().loadDat_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d476db68-39a6-46b8-b168-69a990379b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ceb34eb-bff3-4c9f-9d5b-2164e68495b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 02:26:47,357 - /tmp/ipykernel_2671/3097187596.py[line:41] - INFO: DataLoader loading success\n",
      "2023-10-04 02:26:47,357 - /tmp/ipykernel_2671/3097187596.py[line:41] - INFO: DataLoader loading success\n",
      "2023-10-04 02:26:47,357 - /tmp/ipykernel_2671/3097187596.py[line:41] - INFO: DataLoader loading success\n",
      "2023-10-04 02:26:47,357 - /tmp/ipykernel_2671/3097187596.py[line:41] - INFO: DataLoader loading success\n",
      "2023-10-04 02:26:47,357 - /tmp/ipykernel_2671/3097187596.py[line:41] - INFO: DataLoader loading success\n",
      "2023-10-04 02:26:47,357 - /tmp/ipykernel_2671/3097187596.py[line:41] - INFO: DataLoader loading success\n",
      "2023-10-04 02:26:47,357 - /tmp/ipykernel_2671/3097187596.py[line:41] - INFO: DataLoader loading success\n"
     ]
    }
   ],
   "source": [
    "import logging,os  # 引入logging模块\n",
    "# from com_tools import setting\n",
    "\n",
    "\n",
    "from logging import handlers\n",
    "\n",
    "class Logger(object):\n",
    "    level_relations = {\n",
    "        'debug':logging.DEBUG,\n",
    "        'info':logging.INFO,\n",
    "        'warning':logging.WARNING,\n",
    "        'error':logging.ERROR,\n",
    "        'crit':logging.CRITICAL\n",
    "    }#日志级别关系映射\n",
    "\n",
    "\n",
    "    def __init__(self,filename,level='info',when='MIDNIGHT',backCount=7,fmt='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'):\n",
    "        self.logger = logging.getLogger(filename)\n",
    "        format_str = logging.Formatter(fmt)#设置日志格式\n",
    "        self.logger.setLevel(self.level_relations.get(level))#设置日志级别\n",
    "        sh = logging.StreamHandler()#往控制台输出\n",
    "        sh.setFormatter(format_str) #设置控制台上显示的格式\n",
    "        th = handlers.TimedRotatingFileHandler(filename=filename,interval=1,when=when,backupCount=backCount,encoding='utf-8')#往文件里写入#指定间隔时间自动生成文件的处理器\n",
    "        #实例化TimedRotatingFileHandler\n",
    "        #interval是时间间隔，backupCount是备份文件的个数，如果超过这个个数，就会自动删除，when是间隔的时间单位，单位有以下几种：\n",
    "        # S 秒\n",
    "        # M 分\n",
    "        # H 小时、\n",
    "        # D 天、\n",
    "        # W 每星期（interval==0时代表星期一）\n",
    "        # midnight 每天凌晨\n",
    "        th.suffix = \"%Y-%m-%d.log\" #设置文件后缀\n",
    "        th.setFormatter(format_str)#设置文件里写入的格式\n",
    "        self.logger.addHandler(sh) #把对象加到logger里\n",
    "        self.logger.addHandler(th)\n",
    "# logger = Logger(logfile,level='debug')\n",
    "# logger.info ('DataLoader loading success')\n",
    "logPath = './'\n",
    "logfile = os.path.join(logPath, \"daodianmockapi.txt\") # 这个文件的名称就是当天的日志文件，过往的日志文件，会在后面追加文件后缀 th.suffix\n",
    "logger = Logger(logfile,level='debug')\n",
    "logger.logger.info ('DataLoader loading success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "542e684b-6662-47ca-80f8-2f9013a7972d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install COMTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d67ade-a7a1-4e69-8c90-0eda5028b67e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp/BertClassNews/data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath(os.path.join(os.getcwd(), '..', 'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed57046b-5c2d-464c-9314-cdaa3d2d142c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2cff30-67a6-4ea0-b87f-ef5858490304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "\n",
    "    \"\"\"配置参数\"\"\"\n",
    "    def __init__(self):\n",
    "        self.datPath = '/root/autodl-tmp/BertClassNews/data/'\n",
    "        self.model_dir = 'BertRetrainNewAllDat_v1.pt'\n",
    "        self.wtPath = '/root/autodl-tmp/BertClassNews/wt/'\n",
    "        self.batch_size = 16                                           # mini-batch大小\n",
    "        self.lblEncode = {'本地旅游': 0,\n",
    "                             '通报查处': 1,\n",
    "                             '基建民生': 2,\n",
    "                             '社会热点': 3,\n",
    "                             '暖新闻': 4,\n",
    "                             '人事任免': 5,\n",
    "                             '政策类型': 6,\n",
    "                             '产业金融': 7,\n",
    "                             '人文历史': 8,\n",
    "                             '数据排名': 9}\n",
    "        self.reverse_lblEncode= {0: '本地旅游',\n",
    "                                 1: '通报查处',\n",
    "                                 2: '基建民生',\n",
    "                                 3: '社会热点',\n",
    "                                 4: '暖新闻',\n",
    "                                 5: '人事任免',\n",
    "                                 6: '政策类型',\n",
    "                                 7: '产业金融',\n",
    "                                 8: '人文历史',\n",
    "                                 9: '数据排名'}\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.num_epochs = 3\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "        self.model = BertForSequenceClassification.from_pretrained('bert-base-chinese',num_labels=len(self.lblEncode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081d6e0d-8996-45ff-83c4-2330de3c695f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generateDataloader(df, lbl, Tokenizer, BATCH_SIZE = 16):\n",
    "    inputs = Tokenizer(df, padding=True, truncation=True,return_tensors='pt')\n",
    "    dataset = BERTDataset(inputs, lbl)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbcfa3c7-bffd-4d87-8089-ec6543feccb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, config):\n",
    "    model.to(config.device)\n",
    "    model.eval()\n",
    "    final_pred = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    pred = {i:[] for i in range(len(config.lblEncode))}\n",
    "    # pred = {i:[] for i in [0,2,3]}\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in dataloader:\n",
    "            inputs = torch.stack([t for t in batch['input_ids']]).to(device)\n",
    "            labels = torch.tensor(batch['labels']).to(device)\n",
    "            attention_mask =torch.stack([t for t in batch['attention_mask']]).to(device)\n",
    "            outputs = model(input_ids=inputs, attention_mask=attention_mask,\n",
    "                      labels=labels)\n",
    "            predictions = outputs[1].argmax(dim=1)\n",
    "            for i in range(len(predictions)):\n",
    "                predRes = predictions[i].item()\n",
    "                pred[predRes].append((predictions[i] == labels[i]).item())\n",
    "                final_pred.append((config.reverse_lblEncode[predRes], config.reverse_lblEncode[labels[i].item()]))\n",
    "                # final_pred.append((predRes, labels[i].item()))\n",
    "\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.shape[0]\n",
    "      \n",
    "    accuracy = correct/total\n",
    "    res = {config.reverse_lblEncode[i]:sum(pred[i])/len(pred[i]) if len(pred[i]) > 0 else np.nan for i in pred }\n",
    "    return accuracy, res, final_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43efd64-b3f7-49b8-9265-fd0ee4a2784e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "test_df = pd.read_json(config.datPath + 'test_cls.json') \n",
    "# model, tokenizer = get_token_model(len(config.lblEncode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d91d1e-7c24-447d-81aa-b3cffb08e530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.inputs.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "def save_model(model, wtPath, model_name = 'BertOrigmodelAllDat_v0.pt'):\n",
    "    # datPath = '/root/wt/'\n",
    "    # model_save_path  = datPath + 'BertOrigmodelAllDat_v0.pt'\n",
    "    model_save_path  = wtPath + model_name\n",
    "    if os.path.exists(model_save_path):\n",
    "        loaded_paras = torch.load(model_save_path)\n",
    "        model.load_state_dict(loaded_paras)\n",
    "        logging.info(\"## 成功载入已有模型，进行追加训练......\")\n",
    "    else:\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0beafa5e-ea1b-4bca-b235-7d2254b3f30d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = generateDataloader(test_df['content'].tolist(), test_df['tag'].tolist(), Tokenizer= config.tokenizer, BATCH_SIZE = config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f7c77-031c-4984-97c2-df743473eb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee504ec-640b-4f90-b1ba-b21f5bea554d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simbert不能正常使用，除非你安装：bert4keras、tensorflow ，为了安装快捷，没有默认安装.... No module named 'bert4keras'\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from flask import Flask, jsonify, request\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "sys.path.append(\"/root/autodl-tmp/BertClassNews/\")\n",
    "from config.config import *\n",
    "from load_dataset.load_data_cls import *\n",
    "\n",
    "from train.utils import save_model\n",
    "    \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be8fe51-8a4b-4056-983d-92fc8c9cd01e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/root/autodl-tmp/BertClassNews', '/root/autodl-tmp/BertClassNews')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config().model_config\n",
    "config2 = Config().loadDat_config\n",
    "config.path, config2.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd0d25e4-831f-4c79-b541-ff3c5de76365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = config.model\n",
    "model = save_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bae4054-7360-45e8-8f1c-c94699f4d0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = read_process_cls_dat(config2.Testpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c56865-b15e-46ad-aab7-e75ad56e6875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.to(config.device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0051c917-500f-4a72-a795-a950e2eafd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = config.tokenizer(test_df.head()['content'].tolist(), padding=True, truncation=True,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768b3a0b-7926-4614-882b-9b2c83794017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2408,  691,  ...,    0,    0,    0],\n",
       "        [ 101, 6824, 6226,  ...,    0,    0,    0],\n",
       "        [ 101, 7716, 7491,  ...,    0,    0,    0],\n",
       "        [ 101,  723, 7826,  ...,    0,    0,    0],\n",
       "        [ 101, 6821,  763,  ..., 7905, 1290,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9f72e21-1121-4e06-8bf4-2ea4f967844d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp = torch.stack([t for t in inputs['input_ids']]).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1715bfc4-041e-4ba9-9f78-646d3099d062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_mask =torch.stack([t for t in inputs['attention_mask']]).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87626241-797a-47e1-9f8b-f750b437aecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_type_ids =torch.stack([t for t in test_dataloader['token_type_ids']]).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a13bf-4ad6-4892-9408-4dfe97a14e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(batch['labels']).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f6ea863-fe88-4e63-ba85-3b3554e07f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d81862e0-b8ec-4992-a6d1-9ed8dc2bcfd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = generateDataloader(test_df.head()['content'].tolist(), test_df.head()['tag'].tolist(), config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b41e6301-727a-4def-ba76-3d28b2436c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2408,  691,  ...,    0,    0,    0],\n",
      "        [ 101, 6824, 6226,  ...,    0,    0,    0],\n",
      "        [ 101, 7716, 7491,  ...,    0,    0,    0],\n",
      "        [ 101,  723, 7826,  ...,    0,    0,    0],\n",
      "        [ 101, 6821,  763,  ..., 7905, 1290,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': ['数据排名', '社会热点', '基建民生', '社会热点', '社会热点']}\n"
     ]
    }
   ],
   "source": [
    "for batch in test_dataloader:\n",
    "    print (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ea592be-a56f-4cf8-9be5-d0c89c13db24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model(input_ids=inp, attention_mask=attention_mask,\n",
    "                                   token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a6626c4-1a22-4b2c-ba18-b3508d9dcd19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = outputs[0].argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72f2dd7a-d3b6-43d8-8470-6713f6938538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['数据排名', '社会热点', '暖新闻', '社会热点', '社会热点']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[config.reverse_lblEncode[i] for i in predictions.cpu().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ce689-4e34-4d6e-ae26-c325233ce055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
